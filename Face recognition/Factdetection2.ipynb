{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = face_recognition.load_image_file('face1.jpg')\n",
    "#xác định vị trí khuôn mặt trong ảnh\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph.\n",
      "The chin in this face has the following point: [(50, 111), (49, 129), (51, 146), (54, 164), (59, 182), (68, 198), (80, 211), (95, 222), (113, 225), (131, 223), (145, 214), (159, 201), (169, 186), (175, 168), (177, 148), (179, 129), (179, 110)]\n",
      "The left_eyebrow in this face has the following point: [(58, 100), (64, 90), (76, 86), (88, 87), (100, 90)]\n",
      "The right_eyebrow in this face has the following point: [(122, 90), (135, 86), (147, 86), (159, 90), (167, 100)]\n",
      "The nose_bridge in this face has the following point: [(111, 103), (110, 114), (110, 125), (110, 136)]\n",
      "The nose_tip in this face has the following point: [(99, 145), (105, 147), (111, 150), (117, 148), (123, 146)]\n",
      "The left_eye in this face has the following point: [(73, 106), (80, 102), (88, 102), (95, 107), (87, 108), (79, 108)]\n",
      "The right_eye in this face has the following point: [(129, 107), (136, 102), (144, 102), (151, 106), (145, 108), (137, 108)]\n",
      "The top_lip in this face has the following point: [(85, 167), (94, 164), (103, 163), (111, 165), (119, 164), (129, 165), (140, 169), (136, 169), (119, 168), (111, 169), (103, 168), (89, 168)]\n",
      "The bottom_lip in this face has the following point: [(140, 169), (130, 179), (119, 182), (111, 183), (103, 182), (93, 177), (85, 167), (89, 168), (103, 175), (111, 177), (119, 176), (136, 169)]\n"
     ]
    }
   ],
   "source": [
    "#face landmarks\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "print('I found {} face(s) in this photograph.'.format(len(face_landmarks_list)))\n",
    "\n",
    "#Create a PIL imagedraw object sp we can draw on the picture\n",
    "pil_image = Image.fromarray(image)\n",
    "d = ImageDraw.Draw(pil_image)\n",
    "\n",
    "for face_landmarks in face_landmarks_list:\n",
    "    #Print the location of each facial feature in this page\n",
    "    for facial_feature in face_landmarks.keys():\n",
    "        print('The {} in this face has the following point: {}'.format(facial_feature, face_landmarks[facial_feature]))\n",
    "        \n",
    "    #Let's trace out each facial feature in the large with a line!\n",
    "    for facial_feature in face_landmarks.keys():\n",
    "        d.line(face_landmarks[facial_feature], width=5)\n",
    "\n",
    "#Show the picture\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face recognition\n",
    "#Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "#Load a sample picture and learn how to recognize it\n",
    "long_image = face_recognition.load_image_file('face2.jpg')\n",
    "long_face_encoding = face_recognition.face_encodings(long_image)[0]\n",
    "\n",
    "#Create arrays of known face encoding and their names\n",
    "known_face_encodings = [ long_face_encoding ]\n",
    "known_face_names = [ 'Long', ]\n",
    "\n",
    "while True:\n",
    "    #Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    #Convert the image from BGR color (wwith opencv) to RGB color\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "    \n",
    "    #Find all the faces and face encodings in the front of video\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "    \n",
    "    #Loop throug each face in this frame of video\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        #See if the faces is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        \n",
    "        name = 'Unknown'\n",
    "        \n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "            \n",
    "        #Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        \n",
    "        #Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left -6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "        \n",
    "    #Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    #Hit 'q' on keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
